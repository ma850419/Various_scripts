{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJL3xu3ssuHnJ9MNJy/6g5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ma850419/Various_scripts/blob/main/archeology.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEwKZexlcfRP"
      },
      "outputs": [],
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "openai_to_z_challenge_path = kagglehub.competition_download('openai-to-z-challenge')\n",
        "nikitamanaenkov_brazilian_zooarch_database_zooarchbr_path = kagglehub.dataset_download('nikitamanaenkov/brazilian-zooarch-database-zooarchbr')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "xZMqiFANcryh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install odfpy folium geopy networkx"
      ],
      "metadata": {
        "id": "WPtlXtJ3cvvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import folium\n",
        "import re\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import DBSCAN\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans"
      ],
      "metadata": {
        "id": "56teWbFFc1xI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "bkzOoa2Mc5wB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir(\"/content/drive/My Drive\"))"
      ],
      "metadata": {
        "id": "6h_41cq3c9cI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dms_to_dd(dms):\n",
        "    if pd.isnull(dms): return None\n",
        "    match = re.match(r\"(\\d+)°([EWNS]) (\\d+)' (\\d+)\", str(dms))\n",
        "    if not match: return None\n",
        "    deg, dir_, min_, sec = match.groups()\n",
        "    dd = float(deg) + float(min_)/60 + float(sec)/3600\n",
        "    if dir_ in ['S', 'W']:\n",
        "        dd *= -1\n",
        "    return dd\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/Archeology/Fossile et al. Table 3 (Rev.SAB) - Archaeological Sites.ods\"\n",
        "df = pd.read_excel(file_path, engine=\"odf\")\n",
        "\n",
        "sites = []\n",
        "for idx, row in df.iterrows():\n",
        "    name = row['Archaeological site (*approximate coordinate)']\n",
        "    lon_str = row['Datum SIRGAS2000 (*approximate coordinate)']\n",
        "    lat_str = row['Unnamed: 6']\n",
        "    lon = dms_to_dd(lon_str)\n",
        "    lat = dms_to_dd(lat_str)\n",
        "    if lon is not None and lat is not None:\n",
        "        sites.append({'name': name, 'lat': lat, 'lon': lon})\n",
        "\n",
        "m = folium.Map(location=[-14.2, -51.9], zoom_start=4)\n",
        "for site in sites:\n",
        "    folium.Marker(\n",
        "        [site['lat'], site['lon']],\n",
        "        popup=site['name']\n",
        "    ).add_to(m)\n",
        "\n",
        "m.save('brazil_sites_map.html')\n",
        "m"
      ],
      "metadata": {
        "id": "LnBm_RukdDHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/MyDrive/Archeology/Fossile et al. Table 3 (Rev.SAB) - Archaeological Sites.ods\"\n",
        "#file_path = \"/kaggle/input/brazilian-zooarch-database-zooarchbr/Fossile et al. Table 3 (Rev.SAB) - Archaeological Sites.ods\"\n",
        "df = pd.read_excel(file_path, engine=\"odf\")\n",
        "def dms_to_dd(dms):\n",
        "    import re\n",
        "    if pd.isnull(dms): return None\n",
        "    match = re.match(r\"(\\d+)°([EWNS]) (\\d+)' (\\d+)\", str(dms))\n",
        "    if not match: return None\n",
        "    deg, dir_, min_, sec = match.groups()\n",
        "    dd = float(deg) + float(min_)/60 + float(sec)/3600\n",
        "    if dir_ in ['S', 'W']:\n",
        "        dd *= -1\n",
        "    return dd\n",
        "\n",
        "coords = []\n",
        "names = []\n",
        "print(df.head())\n",
        "for idx, row in df.iterrows():\n",
        "    name = row['Archaeological site (*approximate coordinate)']\n",
        "    lon_str = row['Datum SIRGAS2000 (*approximate coordinate)']\n",
        "    lat_str = row['Unnamed: 6']\n",
        "    lon = dms_to_dd(lon_str)\n",
        "    lat = dms_to_dd(lat_str)\n",
        "    if lon is not None and lat is not None:\n",
        "        coords.append([lat, lon])\n",
        "        names.append(name)\n",
        "\n",
        "coords = np.array(coords)\n",
        "\n",
        "clustering = DBSCAN(eps=0.2, min_samples=2).fit(coords)\n",
        "#clustering = KMeans(n_clusters=5, random_state=42).fit(coords)\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.scatter(coords[:,1], coords[:,0], c=clustering.labels_, cmap='tab10', s=100, label='Sites')\n",
        "plt.xlabel('Longitude')\n",
        "plt.ylabel('Latitude')\n",
        "plt.title('Archaeological Sites Clustering')\n",
        "plt.colorbar(label='Cluster')\n",
        "plt.show()\n",
        "\n",
        "G = nx.Graph()\n",
        "for i, name in enumerate(names):\n",
        "    G.add_node(i, label=name, pos=(coords[i,1], coords[i,0]))\n",
        "\n",
        "for i in range(len(coords)):\n",
        "    for j in range(i+1, len(coords)):\n",
        "        dist = np.linalg.norm(coords[i] - coords[j])\n",
        "        if dist < 0.5:\n",
        "            G.add_edge(i, j, weight=dist)\n",
        "\n",
        "pos = {i: (coords[i,1], coords[i,0]) for i in range(len(coords))}\n",
        "plt.figure(figsize=(12,10))\n",
        "nx.draw(G, pos, with_labels=True, node_size=300, node_color='skyblue')\n",
        "plt.title('Graph of Archaeological Sites by Proximity')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "unique_labels = set(clustering.labels_)\n",
        "for label in unique_labels:\n",
        "    if label == -1:\n",
        "        continue\n",
        "    cluster_coords = coords[clustering.labels_ == label]\n",
        "    centroid = cluster_coords.mean(axis=0)\n",
        "    print(f\"Possible new point near the cluster {label}: {centroid}\")"
      ],
      "metadata": {
        "id": "QQI3eK09dIgw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}